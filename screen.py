#!/usr/bin/env python3
"""
ä»·å€¼å¦ä¸€é¢ - Aè‚¡ä½ä¼°ç­›é€‰å™¨

Usage:
    python screen.py                    # è¿è¡Œç­›é€‰
    python screen.py --limit 20         # ç­›é€‰20åª
    python screen.py --save             # ä¿å­˜åˆ°GitHub
    python screen.py --help             # æŸ¥çœ‹å¸®åŠ©

Examples:
    python screen.py -l 10 -s           # ç­›é€‰10åªå¹¶ä¿å­˜
"""

import argparse
import datetime
import os
import sys
from pathlib import Path

try:
    import pandas as pd
    import tushare as ts
except ImportError:
    print("Error: Missing dependencies. Run: pip install tushare pandas")
    sys.exit(1)

# é…ç½®
DEFAULT_TOKEN = ''  # é»˜è®¤ç©ºï¼Œéœ€è¦é€šè¿‡å‚æ•°ä¼ å…¥
GITHUB_TOKEN = os.environ.get('GITHUB_TOKEN', '')

# GitHubé…ç½®
GITHUB_TOKEN = os.environ.get('GITHUB_TOKEN', '')
REPO_OWNER = 'vaneli5'
REPO_NAME = 'agent-memo'
BRANCH = 'main'


def get_token(token=None):
    """è·å–tushare token: å‚æ•° > ç¯å¢ƒå˜é‡ > ~/.aj-skills/.env"""
    if token:
        return token
    
    # ä¼˜å…ˆè¯»å–ç¯å¢ƒå˜é‡
    token = os.environ.get('TUSHARE_TOKEN')
    if token:
        return token
    
    # è¯»å– ~/.aj-skills/.env
    env_file = Path.home() / ".aj-skills" / ".env"
    if env_file.exists():
        for line in env_file.read_text().splitlines():
            if line.startswith('TUSHARE_TOKEN='):
                return line.split('=', 1)[1].strip()
    
    return ''


def fetch_data(token):
    """è·å–ä»Šæ—¥è¡Œæƒ…æ•°æ®"""
    ts.set_token(token)
    pro = ts.pro_api(token)
    
    # è·å–æœ€è¿‘äº¤æ˜“æ—¥
    today = datetime.datetime.now()
    start_date = (today - datetime.timedelta(days=10)).strftime('%Y%m%d')
    cal_df = pro.trade_cal(exchange='SSE', start_date=start_date, end_date=today.strftime('%Y%m%d'))
    cal_df = cal_df[cal_df['is_open'] == 1].sort_values('cal_date')
    if len(cal_df) > 0:
        trade_date = cal_df.iloc[-1]['cal_date']
    else:
        # å¦‚æœæ²¡æœ‰å¼€å¸‚æ—¥ï¼Œå›é€€åˆ°è·å–æ‰€æœ‰å†å²äº¤æ˜“æ—¥
        cal_df = pro.trade_cal(exchange='SSE', start_date='20250101', end_date=today.strftime('%Y%m%d'))
        cal_df = cal_df[cal_df['is_open'] == 1].sort_values('cal_date')
        trade_date = cal_df.iloc[-1]['cal_date']
    print(f"  ä½¿ç”¨äº¤æ˜“æ—¥: {trade_date}")
    
    # ç›´æ¥è·å–æ‰€æœ‰è‚¡ç¥¨çš„daily_basicï¼ˆåŒ…å«è‚¡æ¯ç‡ï¼‰
    df = pro.daily_basic(
        trade_date=trade_date,
        fields='ts_code,close,pe_ttm,pb,dv_ratio,turnover_rate'
    )
    
    # è·å–è‚¡ç¥¨åç§°ã€è¡Œä¸šã€ä¸Šå¸‚æ—¥æœŸ
    stocks = pro.stock_basic(
        exchange='', 
        list_status='L', 
        fields='ts_code,name,industry,list_date'
    )
    
    # åˆå¹¶åç§°å’Œè¡Œä¸š
    df = df.merge(stocks[['ts_code', 'name', 'industry', 'list_date']], on='ts_code', how='left')
    
    # è¿‡æ»¤STå’ŒåŒ—äº¤æ‰€ã€ç§‘åˆ›æ¿
    df = df[~df['name'].str.contains('ST|é€€', na=False)]
    df = df[~df['ts_code'].str.endswith(('.BJ', '.KCB'))]
    
    return df


def filter_stocks(df, token, pe_max=15, pb_max=2, turnover_min=0.5, roe_min=0, dividend_min=0,
                   no_bank=False, no_broker=False, no_insurance=False, 
                   no_real_estate=False, no_new=False):
    """ç­›é€‰ä½ä¼°è‚¡ç¥¨"""
    if df is None or len(df) == 0:
        return pd.DataFrame()
    
    # æ’é™¤é“¶è¡Œ
    if no_bank:
        df = df[~df['industry'].str.contains('é“¶è¡Œ', na=False)]
    
    # æ’é™¤åˆ¸å•†
    if no_broker:
        df = df[~df['industry'].str.contains('è¯åˆ¸|åˆ¸å•†', na=False)]
    
    # æ’é™¤ä¿é™©
    if no_insurance:
        df = df[~df['industry'].str.contains('ä¿é™©', na=False)]
    
    # æ’é™¤åœ°äº§
    if no_real_estate:
        df = df[~df['industry'].str.contains('æˆ¿åœ°äº§|åœ°äº§', na=False)]
    
    # æ’é™¤æ¬¡æ–°è‚¡
    if no_new:
        one_year_ago = (datetime.datetime.now() - datetime.timedelta(days=365)).strftime('%Y%m%d')
        df = df[df['list_date'] < one_year_ago]
    
    # ç­›é€‰æ¡ä»¶ï¼ˆå…ˆä¸åŠ å…¥ROEå’Œè‚¡æ¯ï¼Œåœ¨åé¢æ·»åŠ ï¼‰
    result = df[
        (df['pe_ttm'] > 0) & (df['pe_ttm'] < pe_max) &
        (df['pb'] > 0) & (df['pb'] < pb_max) &
        (df['turnover_rate'] > turnover_min)
    ].copy()
    
    # å¦‚æœéœ€è¦ROEæˆ–è‚¡æ¯ç­›é€‰ï¼Œè·å–ROEæ•°æ®
    if roe_min > 0 or dividend_min > 0:
        ts.set_token(token)
        pro = ts.pro_api(token)
        
        # è·å–ROEæ•°æ®
        try:
            codes = result['ts_code'].tolist()
            all_roe = []
            for i in range(0, len(codes), 100):
                batch = codes[i:i+100]
                roe_df = pro.fina_indicator(ts_code=','.join(batch), fields='ts_code,roe,end_date')
                if roe_df is not None and len(roe_df) > 0:
                    # å–æœ€æ–°æŠ¥å‘ŠæœŸ
                    roe_df = roe_df.sort_values('end_date', ascending=False).drop_duplicates('ts_code')
                    all_roe.append(roe_df[['ts_code', 'roe']])
            
            if all_roe:
                roe_final = pd.concat(all_roe, ignore_index=True)
                result = result.merge(roe_final, on='ts_code', how='left')
                print(f"  è·å–åˆ° {len(roe_final)} åªROE")
        except Exception as e:
            print(f"  è·å–ROEå¤±è´¥: {e}")
            result['roe'] = None
        
        # ç­›é€‰ROE
        if roe_min > 0:
            before = len(result)
            result = result[result['roe'].fillna(0) > roe_min]
            print(f"  ROE>{roe_min}%: {before} -> {len(result)}")
        
        # ç­›é€‰è‚¡æ¯ç‡
        if dividend_min > 0:
            before = len(result)
            result = result[result['dv_ratio'].fillna(0) > dividend_min]
            print(f"  è‚¡æ¯ç‡>{dividend_min}%: {before} -> {len(result)}")
    
    # æŒ‰PEæ’åº
    result = result.sort_values('pe_ttm')
    
    return result


def show_top3(df, token):
    """å±•ç¤ºå„ç»´åº¦TOP3"""
    if df is None or len(df) == 0:
        print("æ— æ•°æ®")
        return
    
    ts.set_token(token)
    pro = ts.pro_api(token)
    
    # è·å–ROEæ•°æ®
    codes = df['ts_code'].tolist()
    all_roe = []
    for i in range(0, len(codes), 100):
        batch = codes[i:i+100]
        try:
            roe_df = pro.fina_indicator(ts_code=','.join(batch), fields='ts_code,roe,end_date')
            if roe_df is not None and len(roe_df) > 0:
                roe_df = roe_df.sort_values('end_date', ascending=False).drop_duplicates('ts_code')
                all_roe.append(roe_df[['ts_code', 'roe']])
        except:
            pass
    
    if all_roe:
        roe_df = pd.concat(all_roe, ignore_index=True)
        df = df.merge(roe_df, on='ts_code', how='left')
    
    # è¿‡æ»¤åŸºæœ¬æ¡ä»¶
    df = df[(df['pe_ttm'] > 0) & (df['pe_ttm'] < 20) & 
            (df['pb'] > 0) & (df['pb'] < 3) &
            (df['turnover_rate'] > 0.5)]
    
    print("\n" + "="*50)
    print("å„ç»´åº¦TOP3 (PE<20, PB<3, æ¢æ‰‹>0.5%)")
    print("="*50)
    
    # é«˜ROE TOP3
    top_roe = df[df['roe'].notna()].nlargest(3, 'roe')
    print("\nğŸ“ˆ é«˜ROE TOP3:")
    for _, row in top_roe.iterrows():
        print(f"  {row['ts_code']:6} {row['name']:8} PE:{row['pe_ttm']:4.1f} ROE:{row['roe']:5.1f}%")
    
    # é«˜è‚¡æ¯ TOP3
    top_div = df.nlargest(3, 'dv_ratio')
    print("\nğŸ’° é«˜è‚¡æ¯ TOP3:")
    for _, row in top_div.iterrows():
        print(f"  {row['ts_code']:6} {row['name']:8} PE:{row['pe_ttm']:4.1f} è‚¡æ¯:{row['dv_ratio']:5.1f}%")
    
    # ä½PE TOP3
    top_pe = df.nsmallest(3, 'pe_ttm')
    print("\nğŸ” ä½PE TOP3:")
    for _, row in top_pe.iterrows():
        print(f"  {row['ts_code']:6} {row['name']:8} PE:{row['pe_ttm']:4.1f} PB:{row['pb']:4.2f}")
    
    # ä½PB TOP3
    top_pb = df.nsmallest(3, 'pb')
    print("\nğŸ·ï¸ ä½PB TOP3:")
    for _, row in top_pb.iterrows():
        print(f"  {row['ts_code']:6} {row['name']:8} PB:{row['pb']:4.2f} PE:{row['pe_ttm']:4.1f}")
    
    # é«˜ROE+é«˜è‚¡æ¯ï¼ˆåŒé‡ç­›é€‰ï¼‰
    df['score'] = df['roe'].fillna(0) + df['dv_ratio'].fillna(0)
    top_combo = df.nlargest(3, 'score')
    print("\nâ­ é«˜ROE+é«˜è‚¡æ¯ TOP3:")
    for _, row in top_combo.iterrows():
        print(f"  {row['ts_code']:6} {row['name']:8} ROE:{row['roe']:4.1f}% è‚¡æ¯:{row['dv_ratio']:4.1f}% PE:{row['pe_ttm']:4.1f}")


def save_to_github(df, subdir='value-other-side'):
    """ä¿å­˜ç»“æœåˆ°GitHub"""
    import requests
    from base64 import b64encode
    
    if not GITHUB_TOKEN:
        print("Warning: GITHUB_TOKEN not set, skipping save")
        return False
    
    date_str = datetime.datetime.now().strftime('%Y-%m-%d')
    content = df.to_csv(index=False, encoding='utf-8-sig')
    
    filename = f'low_valuation_{date_str}.csv'
    url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{subdir}/data/{filename}"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    response = requests.get(url, headers={'Authorization': f'token {GITHUB_TOKEN}'})
    sha = response.json().get('sha') if response.status_code == 200 else None
    
    # ä¸Šä¼ æ–‡ä»¶
    data = {
        'message': f'update: {date_str} ä½ä¼°è‚¡ç¥¨ç­›é€‰ç»“æœ',
        'content': b64encode(content.encode('utf-8')).decode('utf-8'),
        'branch': BRANCH
    }
    if sha:
        data['sha'] = sha
    
    response = requests.put(url, json=data, headers={'Authorization': f'token {GITHUB_TOKEN}'})
    
    if response.status_code in [200, 201]:
        print(f"âœ“ å·²ä¿å­˜åˆ° GitHub: {subdir}/data/{filename}")
        return True
    else:
        print(f"âœ— ä¿å­˜å¤±è´¥: {response.text}")
        return False


def main():
    parser = argparse.ArgumentParser(
        description='ä»·å€¼å¦ä¸€é¢ - Aè‚¡ä½ä¼°ç­›é€‰å™¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    parser.add_argument('-l', '--limit', type=int, default=30, 
                        help='ç­›é€‰æ•°é‡ (default: 30)')
    parser.add_argument('--pe', type=float, default=15,
                        help='PEæœ€å¤§å€¼ (default: 15)')
    parser.add_argument('--pb', type=float, default=2,
                        help='PBæœ€å¤§å€¼ (default: 2)')
    parser.add_argument('--roe', type=float, default=0,
                        help='ROEæœ€å°å€¼%% (default: 0ï¼Œä¸è¿‡æ»¤)')
    parser.add_argument('--dividend', type=float, default=0,
                        help='è‚¡æ¯ç‡æœ€å°å€¼%% (default: 0ï¼Œä¸è¿‡æ»¤)')
    parser.add_argument('--turnover', type=float, default=0.5,
                        help='æœ€å°æ¢æ‰‹ç‡%% (default: 0.5)')
    parser.add_argument('-t', '--token', type=str, 
                        help='Tushare token (æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ TUSHARE_TOKEN)')
    parser.add_argument('-s', '--save', action='store_true',
                        help='ä¿å­˜ç»“æœåˆ°GitHub')
    parser.add_argument('--no-bank', action='store_true', default=True,
                        help='æ’é™¤é“¶è¡Œè‚¡ (é»˜è®¤å¼€å¯)')
    parser.add_argument('--no-broker', action='store_true', default=True,
                        help='æ’é™¤åˆ¸å•†è‚¡ (é»˜è®¤å¼€å¯)')
    parser.add_argument('--no-insurance', action='store_true', default=True,
                        help='æ’é™¤ä¿é™©è‚¡ (é»˜è®¤å¼€å¯)')
    parser.add_argument('--no-real-estate', action='store_true', default=True,
                        help='æ’é™¤åœ°äº§è‚¡ (é»˜è®¤å¼€å¯)')
    parser.add_argument('--no-new', action='store_true', default=True,
                        help='æ’é™¤æ¬¡æ–°è‚¡ (é»˜è®¤å¼€å¯)')
    parser.add_argument('--include-all', action='store_true',
                        help='ä¸è¿‡æ»¤ï¼ŒåŒ…å«æ‰€æœ‰è‚¡ç¥¨')
    parser.add_argument('--top3', action='store_true',
                        help='å±•ç¤ºå„ç»´åº¦TOP3')
    
    args = parser.parse_args()
    
    # ä¼˜å…ˆç”¨å‚æ•°ï¼Œå…¶æ¬¡ä»ç¯å¢ƒå˜é‡/é…ç½®æ–‡ä»¶è¯»å–
    token = args.token if args.token else get_token()
    
    if not token:
        print("Error: è¯·ä¼ å…¥ Tushare token")
        print("  - é€šè¿‡å‚æ•°: python screen.py -t YOUR_TOKEN")
        print("  - æˆ–è®¾ç½®ç¯å¢ƒå˜é‡: export TUSHARE_TOKEN=YOUR_TOKEN")
        print("  - æˆ–é…ç½®åœ¨ ~/.aj-skills/.env")
        sys.exit(1)
    
    print("=" * 50)
    print("ä»·å€¼å¦ä¸€é¢ - Aè‚¡ä½ä¼°ç­›é€‰å™¨")
    print(f"ç­›é€‰æ¡ä»¶: PE<{args.pe}, PB<{args.pb}, æ¢æ‰‹>{args.turnover}%")
    print("=" * 50)
    
    # è·å–æ•°æ®
    print("\n[1/2] è·å–è¡Œæƒ…æ•°æ®...")
    df = fetch_data(token)
    if df is None or len(df) == 0:
        print("âœ— è·å–æ•°æ®å¤±è´¥")
        sys.exit(1)
    print(f"  è·å–åˆ° {len(df)} åªè‚¡ç¥¨")
    
    # å¦‚æœæ˜¯top3æ¨¡å¼
    if args.top3:
        show_top3(df, token)
        return
    
    # ç­›é€‰
    print("\n[2/2] ç­›é€‰ä½ä¼°è‚¡ç¥¨...")
    
    # é»˜è®¤æ’é™¤é“¶è¡Œ/åˆ¸å•†/ä¿é™©/åœ°äº§/æ¬¡æ–°è‚¡
    if not args.include_all:
        result = filter_stocks(
            df, token,
            pe_max=args.pe, 
            pb_max=args.pb,
            turnover_min=args.turnover,
            roe_min=args.roe,
            dividend_min=args.dividend,
            no_bank=True,
            no_broker=True,
            no_insurance=True,
            no_real_estate=True,
            no_new=True
        )
    else:
        result = filter_stocks(
            df, token,
            pe_max=args.pe, 
            pb_max=args.pb,
            turnover_min=args.turnover,
            roe_min=args.roe,
            dividend_min=args.dividend
        )
    
    result = result.head(args.limit)
    print(f"  ç­›é€‰å‡º {len(result)} åª")
    
    # å±•ç¤ºç»“æœ
    print("\n" + "=" * 50)
    print(f"ä½ä¼°è‚¡ç¥¨TOP{len(result)}:")
    print("=" * 50)
    
    display_cols = ['code', 'name', 'close', 'pe', 'pb', 'turnoverratiof']
    display_cols = [c for c in display_cols if c in result.columns]
    
    for i, row in result.iterrows():
        print(f"{row.get('ts_code', ''):6} {row.get('name', ''):8} "
              f"ç°ä»·:{row.get('close', 0):6.2f} "
              f"PE:{row.get('pe_ttm', 0):6.1f} "
              f"PB:{row.get('pb', 0):4.2f} "
              f"ROE:{row.get('roe', 0):4.1f}% "
              f"è‚¡æ¯:{row.get('dv_ratio', 0):4.1f}% "
              f"æ¢æ‰‹:{row.get('turnover_rate', 0):4.1f}%")
    
    # ä¿å­˜
    if args.save:
        save_to_github(result)
    
    print(f"\nå®Œæˆ! å…± {len(result)} åª")


if __name__ == '__main__':
    main()
